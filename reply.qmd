---
title: "reply"
format: html
editor: visual
---

# Review 1

## General

This paper concerns the CRAN package cassowaryr for calculating scagnostics. This package is an alternative to the existing scagnostics package, with the code now written in R, and some improvements made to the definition of the scagnostics themselves. Scagnostics are a very useful tool for screening scatterplots, and their existing implementation in the scagnostics package are known to have some flaws. This new package, particularly as it is tidyverse friendly, could help promote scagnostics as a tool to the R community.

Very little of the paper is given over to the package, its design and implementation. No comparison is made to the original scagnostics package.Though binning is mentioned in the paper, it is not available in the package. Presumably if it did include binning, then the original scagnostic definitions should be used. Presumably also, the new implementation of scagnostics is a lot slower than the original due to the R vs C++ implementation and the lack of binning, though this is not discussed. **Want comparison to scagnostics package. Package had issues with it. Hadley has similar code in the binostics package that has an underlying one. Could try doing that. Not sure how time comparison will work (since not in R) also no binning so hard to compare.**

Much of the paper is given over to four examples, though code is not given. While the examples are very interesting, four examples is excessive. Particularly the third example is a bit "meta" (scagnostics of scagnostics...) and is rather complex for the current paper.

**See detailled comments**

RJ papers concerning a package should include more than just a little code demonstrating the package.

## Detailed comments

**Page 1: There is extended discussion of dimension reduction in the first paragraph. This is not directly relevant to the topic at hand, and should be reduced to a sentence or two.** 
We agree and have reduced that section to a few sentences.

**The word "biplots" is used a few tines as a replacement for "scatterplot". This usage is incorrect: a biplot is where you show variables and cases on the same plot. **
We agree and have made the changes.

**Page 1: Par 2 scagnostics produce a hierarchy of variable pairs, not variables. Tukey reference in this paragraph needs fixing.**
We agree and have made the changes.

**Page 2: "Before any of the scagnostics are calculated, outlying points are removed." Surely not true for outlying, monotonic and other association-based measures? **
Outlying uses both, monotonic and other association-based use the MST that has outlying points removed.
- This is actually a good point, and I am a but unsure whether to fix this, or reply.
- There are actually a few sections in the scagnostics distributions paper that make it unclear how outliers were originally supposed to be removed
  - A.2 - Preprocessing - "We bin our data and delete outliers before computing our geometric graphs." 
    - This would include the MST and Hull measures, but not the association measures
  - A.3.1 - Outlying - "Note that we do this calculation before deleting outliers for the other measures"
    - Implies this is done and then every other metric is calculated without outliers, including association measures such as monotonic (since it follows outlying in this list)
- In cassowaryr, I removed outliers for all scagnostics (other than outlying) to maintain consistency. So you knew the scagnostics the function spit out were all calculated on the same underlying plot.
- Quite frankly, I think the outlying removal option should be set to FALSE by default (it is currently set to TRUE). If scagnostics should be an EDA tool, then I feel like the default should be calculated on the scatter plot put into the function. Removing the outliers can actually change the visual structure of the plot quite significantly.


**Page 2 "to range" -\> "to range in" **
We agree and have made the changes.

**Page 4: description of sparse: "Identifies if the data is sporadically located on the plane." This does not make sense to me. **
Good point. We changed the wording so it is more in line with the original explanation from the Scacnostic Distributions paper. It now reads "Identifies if the data is confined to a small number of locations on the plane". 

**Page 5: For dcor include a reference to distance corrrelation. **
Good catch. We have added the reference to distance correlation.

**Page 5: In the discussion of Figure 4, you point out problems with the original scagnostic measures. When comparing this to Figures 4 and 6 of the Wilkinson and Wills (2008) paper, it would seem more than a suspicion that the defects evident in Figure 4 are due to binning. Why not verify this using the scagnostics package?** 
If easy we can check this with the binostics package.

**Page 6: Table 1: As regards stringy, it says "This measure rarely drops below 0.5", but this does not agree with the Wilkinson and Wills figures 5 and 6.**
We agree that this does not agree with the Wilksinson and Wills figures 5 and 6. This is why it was listed as an "issue" with our calculation of the measure and we explcitly mention this issue did not exist in the binned version of the statistics. The issues table outlines problems with the cassowaryr computations of the measures. Some of them overlap with issues that might arrise in the Wilkinson (2008) calculations, but some of them are unique to the cassowaryr computation.

**Page 7: "in contention with" -\> "align with" ? **
We are saying that the measures do not align with human intuition, but agree that phrase is needlessly complicated. We changed it to "conflicts with"*

**Page 7: The discussion of Figure 5 is confusing. The "line" plot does not score 1 on either striated measure. The caption says "line and vlines have the same result" but this is not evident in the display.**
- This is actually an issue caused by interp package that I missed (and also why I am eternally annoyed that Albrech would not use the tRiad package)
- I suspect the noise added in the line plot causes the MST edges to go beyond the error tollerance for the striated measure.
- I might be able to fix this by tinkering with the error tollerance in the striated measure
- Good catch by the reviewer tbh

**Page 13: Figure 7 In the caption it refers to the black edge, do you mean green?**
We agree and have made the changes.

**Page 13: In the discussion associates with Figure 8, you mention picking scatterplots with a low scagnostic value. Why would you do this? Up to now, it seems you were looking for high scagnostic scores.**

Up to this point in the paper, we were assessing the scagnostics with the features data, so we were hoping the scatter plots that typified each feature would have a high value on its respective scagnostic (e.g. the clusters plot would have the highest clumpy measure) for each index (i.e. trying to design ). 

In the AFLW example, we are using the scagnostics to explore the data and identify interesting structures. For this reason, we are no longer looking for high or low values perse, but rather unusual scagnostic values. This is also done in the Scagnostics Distributions paper (Figure 2). The idea is that these outliers should identify plots that are visibly dissimilar from other scatter plots in the data set and might have an unexpected structure.

We agree that this approach should have been mentioned earlier in the paper. We have now included a sentence in the third paragraph of the introduction that mentions using a SPLOM of scagnostic values as an EDA technique. We also included a more detailling introduction to the approach in the first paragraph of the AFLW example. 

- "should be in package documentation" - note from meeting with Ursula, not sure what this means


**In Figure 9 top row the coloured dots are hard to pick out. I suggest you make them bigger.** 
We agree. We made them bigger and added a black outline.

**In Figure 10. explain that the blue/red dots represent the same plots in the three scagnostic plots. Again coloured dots are small, suggest making them bigger.**
We agree and have made the changes.

**Figure 11: I would not describe the green plot (alpha vs time) as exhibiting clumpiness.** While they are not elliptical, the plot does show two disconnected regions of higher density, and we would expect the clumpy index to be sensitive to this gap pattern. XXX need some rephrasing in the text? maybe clumpy is better described as a gap pattern?

**Page 13: "The best way to identify interesting scatter plots is to construct a large interactive SPLOM" This statement needs more justification. Why a SPLOM as opossed to another display of multivariate data? I would like to see this interactive SPLOM included (and suggest dropping the final two examples.) It would be nice if your package included some functionality to identify interesting scatterplots, beyond top_pairs, which is not used in any of the examples. **
In original paper they do SPLOM. Don't have to say its the best way, could also make parallel coordinate plot. Change phrasing. Whole splom would take up a lot of space in the paper.

**Page 14: "The splines vs dcor plot tells us that there is a strong linear relationship". But both of these are measures of non-linear association.**
Would have to look it up, there should be some papers that say the highest values in distance correlation (close to 1) only happens with linear relationships. Check for paper on that. If not just say strong relationship**

**Page 14: the scagnostics for the physics data are computed on a sample of 200 out of \~10K observations. Binning would be very useful in this case. Presumably outliers could easily be "lost" in such a small sample.**
We are looking for the main patterns and not for outliers, but we agree that if binning is available then it could be the full data. We have adjusted the phrasing to clarify this.**

**Page 16: The statement about LDA assumptions is incorrect. In any case, the LDA/QDA discussion is not directly relevant.**
(Di problem)

**Page 17: PCA regression description is not accurate, as the dimension reduction steps and regression are performed independently. Suggest removing the discussion about pca, it is not really relevant and is confusing. **
(Di problem)

**Page 17: "Macroeconomic series tend to have moderate curvature and varied trend, while microeconomic series tend to have strong trends and varied curvature." How is this statement supported by figure 13, where trends look about the same between micro and micro series? Then the Figure caption says "The way that trend strength is calculated, on closer inspection, could lead to describing jagginess." which seems strange and could do with more explanation. **
(Di problem)

**This third example is scagnostics calculated on features of time series rather than time series themselves. This is an interesting idea, but needs to be motivated. Also the code provided for this example is not self-contained, as the code for calculation of the feasts indices is not provided. **
(Di problem)

**Page 19: In the WBI example (Fig 14) the top clumpy2 value is (close to) 1, yet the scatterplot is not what I'd describe as clumpy. Is this a problem with the index? **
(Di problem)

**Page 19: "This tells us that in the WBI data, the relationships between variables is dominated by outliers (as noted by the high values on the outlying scagnostic, and to some extent also skewed and stringy), and no relationship (given bu the high values on convex). " There is something wrong with this sentence. **
(Di problem)

**Some references in the paper use the author's first initial/name. **
We agree and have made the changes.

**Chapter 10 of PhD thesis of Adam Rahman is relevant: https://core.ac.uk/download/pdf/158325743.pdf **
Ursula looked, I can also check. Changed some definitions and stuff. Might want to reference these types of adjustment exist and have been done before

## Code

**For the features data, would be useful if these patterns could be generated with different amounts of noise. **
If functional dependence it is easy, but for the other ones it is not clear how you would add noise. Can simulate first then add noise on top if desperate.**

**Data with NA generates an error. **
Should check this, shouldnt happen, will fix if it does.

**The function calc_scags has an argument euclid which is not explained. **
So true. Either explain or remove I guess.

**calc_scags has no option to bin the data. **
You can't. Should make it clearer in the paper there is no binning.

**The package has no vignettes, beyond the README **
There is a vignette [here](https://numbats.github.io/cassowaryr/articles/cassowaryr.html). Do they want it longer?

# Review 2

## General

The article outlines the most common scagnostic measures and introduces improvements to fix undesirable behaviour in the patterns they highlight and make them more intuitive. After discussing the implementation in `cassowaryr`, several examples and tests demonstrate the use of scagnostics and `cassowaryr` in practice.

This paper is a welcome addition to the literature on scagnostics. By nature, these are applied measures, but some previous works do not present them in an applied way. Here, an appropriate amount of theory is presented with an outline of a software package and many worked examples to emphasize the package's intended use. The equal emphasis on all three aspects of scagnostics is a perfect accompaniment to a package intended for widespread use and a nice way to introduce the topic.

There are several major areas which could be improved, however. First, major edits of the writing are required. Simple typos are present in most sections and many of the sentences have awkward wording, detracting from the tutorial the paper intends to deliver. The detailed comments below identify many of these but there are likely others which have been missed.

A second major issue is the introduction of the scagnostics. While the choice to make it brief and minimally theoretical is appropriate, for several of the scagnostics this unfortunately makes the formulas presented confusing or even impossible to understand. In particular, dcor is presented without the necessary context to understand the notation used in its definition. A better balance must be struck between context and brevity when defining the measures if formulas are to be provided in their definitions. Alternatively, more detailed descriptions of these scagnostics could be combined with references to the appropriate papers giving their formulas.

**Come back to this after detailled comments**

Finally, the title seems problematic. It is an awkward way to express the content of the article and is likely to misleading many readers. Given the pace and high publicity of research in computational statistics around 'teaching' computers to do tasks such as object recognition, speech, and translation, it seems unwise to use the term for an article which presents methods designed for human interpretation. Emphasizing the computer and claiming to 'teach' it to 'see' with scagnostics is exaggerated and gives the wrong impression of the article's content. **I agree, although it was less of an issue when we originally wrote the paper (four years ago). The title has been changed.**

## Detailed comments

Consider reordering Table 1 and Figure 3 for clarity, skipping one to read the other breaks the flow of the article. **We agree and have made the changes.**

-   Clean up references and make them consistent (some use first names, others use abbreviations, still others a mix of both: this makes for jarring and confusing reading) **We agree and have made the changes.**

-   last paragraph of introduction, line 5, "scagnostics" should be "scagnostics'" **We agree and have made the changes.**

-   last sentence of first paragraph of introduction: wording feels clunky, maybe change 'is' to 'are' and drop the 'even' **We agree and have made the changes.**

-   outlying description on page 4: 'dataset' is missing an article ('the dataset', perhaps) **We agree and have made the changes.**

-   stringy description on page 4: would benefit from explicitly stating the vertices are from the MST, all other descriptions are explicit about using the MST, A, or C **We agree and have made the changes.**

-   introduction of DCor on page 5: must define and describe what a\_{kl} and b\_{kl} are, otherwise the equation should not be provided and left in references **We agree and have made the changes.**

-   page 5, first sentence of Checking Scagnostics Calculations: missing apostrophe on "package's" **We agree and have made the changes.**

-   skewed description in table 1 seems to be missing 's' on the verbs, "reguarding" is spelled incorrectly rather than "regarding" **We agree and have made the changes.**

-   page 7: how strict is the restriction around 180 & 90 degrees? **We agree. To make it clear we have changed the sentence to: \_\_\_\_**

-   page 7: last paragraph is highly confusing... what is the 'lines' scatterplot referenced and how does it differ from 'vlines'? The later comments make sense but the whole discussion is made confusing by errors like this **Check if lines should be vline or line or both? We agree. To make it clear we have changed the sentence to: \_\_\_\_**

-   page 7, last paragraph: 'axis' should be 'axes', 'observation' should be plural, 'version' should be plural **We agree and have made the changes.**

-   page 9, clumpy adjusted point 3: reword to be 'vertices with adjacent angles forming' **I think I specifically tried to use the terminology from the original scagnostics paper to keep it consistent. Check that. But also, if the reviewer was confused, we should probably reword this so it is clearer.**

-   table 3 on page 11 has some typos: 'stirated', 'scagnositc', etc. **We agree and have made the changes.**

-   page 11, calculate functions: '...each function is a scagnostics' should not be pluralized **We agree and have made the changes.**

-   page 12, making summaries: 'summarise' should be 'summaries' **We agree and have made the changes.**

-   page 13, end of page: spaces missing in '...SPLOM of the scagnostic values,each..." and 'Plot2' **We agree and have made the changes.**

-   page 14, non-linear shapes section: first sentence has somewhat awkward wording, the use of 'that's' is incorrect **We agree and have rephrased the sentence.**

-   page 15: 'except' should be 'expect' **We fixed the typo.**

-   page 16: '...from each groups' should be "...from each group's" **Di section**

-   page 17: '...utilising the scagnostics' should be "...utilising the scagnostics'" **Di section**

-   page 18, figure 13 caption: by 'jagginess', is 'jaggedness' meant? **Di section**

-   page 19, figure 14: the description of the figure states that only a single pair ranked highest on striated2, but two points can be observed in the plot, what is the cause of this discrepancy? The caption also seems to state something different **Di section**

-   page 19: '...between variables is...' should be '...between variables are...' **Di section**

-   page 19: 'bu' should be 'by' **Di section**

-   page 19: missing apostrophe on 'packages' (should be 'package's') **We agree and have made the changes.**

## Code

Usability:

The documentation is thin, but this is appropriate with the vignette provided and the simplicity of the intended workflow. This package is highly user-friendly and accessible. **Thanks**

Code:

While the code is generally robust to different patterns in the data, there seem to be a few edge cases where its behaviour is undesirable and it returns strange errors. Using it on the `anscombe_tidy` data,

```         
for (ii in 1:4)
   test[[ii]] <- calc_scags(anscombe_tidy$x[anscombe_tidy$set == ii],
                            anscombe_tidy$y[anscombe_tidy$set == ii])
```

for example, gives the error: "In alphahull::areaahull(y) : Problem in area computation (Returns NA)" for the last two patterns. The table returned either contains only NAs or has no rows. It seems the removal of the outlying points in these two patterns leads to an alpha hull around a perfectly straight line and this causes the code to fail. In addition to this failure, the error provided is somewhat uninformative to the user, and could only be deciphered here because of the simplicity of the data. **Should check this, shouldnt happen, will fix if it does.**

The functions are clearly named, and the code is well-organized and understandable.
